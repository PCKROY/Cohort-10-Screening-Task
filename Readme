Cohort Task 1.1 file contains 'Naive Simulation using Matrix Multiplication' task. 
In this file, I have defined a quantum circuit that consists of X, H, CNOT and Identity gates.
What I did was I supposed if we have 3 qubits and CNOT is applied on the first 2, then an Identity gate is applied on the 
last qubit. Then I did a tensor between the CNOT and Identity matrix gates which gave me a matrix that can be applied to the state.
First I initialized the state with 'initialize_state' functuion. Then I applied the gates sequentially with 'apply_single_qubit_gate'
and 'apply_cnot' functions and simulated the ciruit. Then with 'measure_runtime' function, I ploted the runtime of the number of qubits.
In this way, I only ploted 14 qubits in this file.

Cohort task 1.2 file contains 'Advanced simulation using tensor multiplication' task.
In this file, I have did almost the same thing that I did for the Cohort task 1.1
But in here, I built quantum tensor state and then I applied the gates X, H, CNOT sequentially to the quantum tensor state 
by doing tensor multiplication (np.tensordot). Then I ploted the runtime of the number of qubits by measure_runtime().
In this way, I can simulate only upto 4 qubits. 

Comparing the results from subtask 1 (statevector representation) and subtask 2 (tensor representation), we can observe several important points:
1. The statevector representation (subtask 1) is significantly faster than the tensor representation (subtask 2) for the same number of qubits.
2. The statevector representation scales better with increasing number of qubits. Subtask 1 could simulate up to 14 qubits in about 10 seconds 
where Subtask 2 only managed 4 qubits in the same timeframe.
3. Both methods show exponential growth in runtime as the number of qubits increases, but the growth is much steeper for the tensor representation.
4. The tensor representation becomes impractical very quickly, with just 4 qubits taking over 2 seconds. The statevector representation remains usable for a larger number of qubits, up to 14 in the test.
5. Although not directly measured, but quickly we know that Subtask 2 method becomes slower, means it is very much memory intensive than Subtask 1.


